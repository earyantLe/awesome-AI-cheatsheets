{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T03:03:26.499467Z",
     "start_time": "2024-04-23T03:03:25.598872Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.compat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfa\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow_addons/__init__.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m _check_tf_version()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Local project imports\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callbacks\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow_addons/activations/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Additional activation functions.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgelu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gelu\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhardshrink\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hardshrink\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlisht\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lisht\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow_addons/activations/gelu.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorLike\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mregister_keras_serializable(package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddons\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgelu\u001b[39m(x: TensorLike, approximate: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Gaussian Error Linear Unit.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    Computes gaussian error linear:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m        A `Tensor`. Has the same type as `x`.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow_addons/utils/types.py:29\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# TODO: Remove once https://github.com/tensorflow/tensorflow/issues/44613 is resolved\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Version(tf\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mrelease \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.13\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrelease:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# New versions of Keras require importing from `keras.src` when\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# importing internal symbols.\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m Version(tf\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mrelease \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrelease:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/engine/keras_tensor.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras Input Tensor used to track functional API Topology.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m object_identity\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.compat'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04cc0c5634003a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:58:52.105741Z",
     "start_time": "2024-04-23T02:57:46.962401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: tensorflow in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-addons in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (0.23.0)\n",
      "Requirement already satisfied: pandas in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (3.8.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Python/3.9/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.3.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.62.2)\n",
      "Requirement already satisfied: setuptools in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: packaging in /Library/Python/3.9/site-packages (from tensorflow) (24.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Python/3.9/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorflow-addons) (2.13.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Python/3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Library/Python/3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.18.1)\n",
      "Requirement already satisfied: rich in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Python/3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Python/3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Python/3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Python/3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Library/Python/3.9/site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Python/3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Python/3.9/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/lirui23/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!/usr/bin/pip3 install -U tensorflow tensorflow-addons pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "705529cff78a6906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (32561, 15)\n",
      "Test dataset shape: (16282, 15)\n"
     ]
    }
   ],
   "source": [
    "CSV_HEADER = [\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education_num\",\n",
    "    \"marital_status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"gender\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "    \"native_country\",\n",
    "    \"income_bracket\",\n",
    "]\n",
    "train_data_url = (\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    ")\n",
    "train_data = pd.read_csv(train_data_url, header=None, names=CSV_HEADER)\n",
    "test_data_url = (\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\"\n",
    ")\n",
    "test_data = pd.read_csv(test_data_url, header=None, names=CSV_HEADER)\n",
    "print(f\"Train dataset shape: {train_data.shape}\")\n",
    "print(f\"Test dataset shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "214a52141f090d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data[1:]\n",
    "test_data.income_bracket = test_data.income_bracket.apply(\n",
    "    lambda value: value.replace(\".\", \"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83aa7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"train_data.csv\"\n",
    "test_data_file = \"test_data.csv\"\n",
    "train_data.to_csv(train_data_file, index=False, header=False)\n",
    "test_data.to_csv(test_data_file, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "713eba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 数值特征字段\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "    \"age\",\n",
    "    \"education_num\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "]\n",
    "## 类别型特征字段及其取值列表\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
    "    \"workclass\": sorted(list(train_data[\"workclass\"].unique())),\n",
    "    \"education\": sorted(list(train_data[\"education\"].unique())),\n",
    "    \"marital_status\": sorted(list(train_data[\"marital_status\"].unique())),\n",
    "    \"occupation\": sorted(list(train_data[\"occupation\"].unique())),\n",
    "    \"relationship\": sorted(list(train_data[\"relationship\"].unique())),\n",
    "    \"race\": sorted(list(train_data[\"race\"].unique())),\n",
    "    \"gender\": sorted(list(train_data[\"gender\"].unique())),\n",
    "    \"native_country\": sorted(list(train_data[\"native_country\"].unique())),\n",
    "}\n",
    "## 权重字段\n",
    "WEIGHT_COLUMN_NAME = \"fnlwgt\"\n",
    "## 类别型字段名称\n",
    "CATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURES_WITH_VOCABULARY.keys())\n",
    "## 所有的输入特征\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "## 默认填充的取值\n",
    "COLUMN_DEFAULTS = [\n",
    "    [0.0] if feature_name in NUMERIC_FEATURE_NAMES + [WEIGHT_COLUMN_NAME] else [\"NA\"]\n",
    "    for feature_name in CSV_HEADER\n",
    "]\n",
    "## 目标字段\n",
    "TARGET_FEATURE_NAME = \"income_bracket\"\n",
    "## 目标字段取值\n",
    "TARGET_LABELS = [\" <=50K\", \" >50K\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbbcbe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学习率\n",
    "LEARNING_RATE = 0.001\n",
    "# 学习率衰减\n",
    "WEIGHT_DECAY = 0.0001\n",
    "# 随机失活 概率参数\n",
    "DROPOUT_RATE = 0.2\n",
    "# 批数据大小\n",
    "BATCH_SIZE = 265\n",
    "# 总训练轮次数\n",
    "NUM_EPOCHS = 15\n",
    "# transformer块的数量\n",
    "NUM_TRANSFORMER_BLOCKS = 3\n",
    "# 注意力头的数量\n",
    "NUM_HEADS = 4\n",
    "# 类别型embedding嵌入的维度\n",
    "EMBEDDING_DIMS = 16\n",
    "# MLP隐层单元数量\n",
    "MLP_HIDDEN_UNITS_FACTORS = [\n",
    "    2,\n",
    "    1,\n",
    "]\n",
    "# MLP块的数量\n",
    "NUM_MLP_BLOCKS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "610c5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label_lookup = layers.StringLookup(\n",
    "    vocabulary=TARGET_LABELS, mask_token=None, num_oov_indices=0\n",
    ")\n",
    "def prepare_example(features, target):\n",
    "    target_index = target_label_lookup(target)\n",
    "    weights = features.pop(WEIGHT_COLUMN_NAME)\n",
    "    return features, target_index, weights\n",
    "# 从csv中读取数据\n",
    "def get_dataset_from_csv(csv_file_path, batch_size=128, shuffle=False):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        column_names=CSV_HEADER,\n",
    "        column_defaults=COLUMN_DEFAULTS,\n",
    "        label_name=TARGET_FEATURE_NAME,\n",
    "        num_epochs=1,\n",
    "        header=False,\n",
    "        na_value=\"?\",\n",
    "        shuffle=shuffle,\n",
    "    ).map(prepare_example, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "    return dataset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50e788ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    model,\n",
    "    train_data_file,\n",
    "    test_data_file,\n",
    "    num_epochs,\n",
    "    learning_rate,\n",
    "    weight_decay,\n",
    "    batch_size,\n",
    "):\n",
    "    # 优化器\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "    # 模型编译\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\")],\n",
    "    )\n",
    "    # 训练集与验证集\n",
    "    train_dataset = get_dataset_from_csv(train_data_file, batch_size, shuffle=True)\n",
    "    validation_dataset = get_dataset_from_csv(test_data_file, batch_size)\n",
    "    # 模型训练\n",
    "    print(\"Start training the model...\")\n",
    "    history = model.fit(\n",
    "        train_dataset, epochs=num_epochs, validation_data=validation_dataset\n",
    "    )\n",
    "    print(\"Model training finished\")\n",
    "    # 模型评估\n",
    "    _, accuracy = model.evaluate(validation_dataset, verbose=0)\n",
    "    print(f\"Validation accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe32180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURE_NAMES:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.float32\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.string\n",
    "            )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eebc148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_inputs(inputs, embedding_dims):\n",
    "    encoded_categorical_feature_list = []\n",
    "    numerical_feature_list = []\n",
    "    for feature_name in inputs:\n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "            # 获取类别型特征的不同取值(vocabulary)\n",
    "            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
    "            # 构建lookup table去构建 类别型取值 和 索引 的相互映射\n",
    "            lookup = layers.StringLookup(\n",
    "                vocabulary=vocabulary,\n",
    "                mask_token=None,\n",
    "                num_oov_indices=0,\n",
    "                output_mode=\"int\",\n",
    "            )\n",
    "            # 类别型字符串取值 转为 整型索引\n",
    "            encoded_feature = lookup(inputs[feature_name])\n",
    "            # 构建embedding层\n",
    "            embedding = layers.Embedding(\n",
    "                input_dim=len(vocabulary), output_dim=embedding_dims\n",
    "            )\n",
    "            # 为索引构建embedding嵌入\n",
    "            encoded_categorical_feature = embedding(encoded_feature)\n",
    "            encoded_categorical_feature_list.append(encoded_categorical_feature)\n",
    "        else:\n",
    "            # 数值型特征\n",
    "            numerical_feature = tf.expand_dims(inputs[feature_name], -1)\n",
    "            numerical_feature_list.append(numerical_feature)\n",
    "    return encoded_categorical_feature_list, numerical_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37a7d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(hidden_units, dropout_rate, activation, normalization_layer, name=None):\n",
    "    mlp_layers = []\n",
    "    for units in hidden_units:\n",
    "        mlp_layers.append(normalization_layer),\n",
    "        mlp_layers.append(layers.Dense(units, activation=activation))\n",
    "        mlp_layers.append(layers.Dropout(dropout_rate))\n",
    "    return keras.Sequential(mlp_layers, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd6d9b4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# 完整的模型\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m baseline_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_baseline_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEMBEDDING_DIMS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_mlp_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_MLP_BLOCKS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmlp_hidden_units_factors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMLP_HIDDEN_UNITS_FACTORS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDROPOUT_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal model weights:\u001b[39m\u001b[38;5;124m\"\u001b[39m, baseline_model\u001b[38;5;241m.\u001b[39mcount_params())\n\u001b[1;32m     49\u001b[0m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mplot_model(baseline_model, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rankdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m, in \u001b[0;36mcreate_baseline_model\u001b[0;34m(embedding_dims, num_mlp_blocks, mlp_hidden_units_factors, dropout_rate)\u001b[0m\n\u001b[1;32m      5\u001b[0m inputs \u001b[38;5;241m=\u001b[39m create_model_inputs()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 特征编码\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m encoded_categorical_feature_list, numerical_feature_list \u001b[38;5;241m=\u001b[39m \u001b[43mencode_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dims\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 拼接所有特征\u001b[39;00m\n\u001b[1;32m     11\u001b[0m features \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[1;32m     12\u001b[0m     encoded_categorical_feature_list \u001b[38;5;241m+\u001b[39m numerical_feature_list\n\u001b[1;32m     13\u001b[0m )\n",
      "Cell \u001b[0;32mIn[15], line 26\u001b[0m, in \u001b[0;36mencode_inputs\u001b[0;34m(inputs, embedding_dims)\u001b[0m\n\u001b[1;32m     23\u001b[0m         encoded_categorical_feature_list\u001b[38;5;241m.\u001b[39mappend(encoded_categorical_feature)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;66;03m# 数值型特征\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m         numerical_feature \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m         numerical_feature_list\u001b[38;5;241m.\u001b[39mappend(numerical_feature)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoded_categorical_feature_list, numerical_feature_list\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/backend/common/keras_tensor.py:91\u001b[0m, in \u001b[0;36m__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "def create_baseline_model(\n",
    "    embedding_dims, num_mlp_blocks, mlp_hidden_units_factors, dropout_rate\n",
    "):\n",
    "    # 创建输入.\n",
    "    inputs = create_model_inputs()\n",
    "    # 特征编码\n",
    "    encoded_categorical_feature_list, numerical_feature_list = encode_inputs(\n",
    "        inputs, embedding_dims\n",
    "    )\n",
    "    # 拼接所有特征\n",
    "    features = layers.concatenate(\n",
    "        encoded_categorical_feature_list + numerical_feature_list\n",
    "    )\n",
    "    # 前向计算\n",
    "    feedforward_units = [features.shape[-1]]\n",
    "    # 构建全连接，并且添加跳跃连接(skip-connection)\n",
    "    for layer_idx in range(num_mlp_blocks):\n",
    "        features = create_mlp(\n",
    "            hidden_units=feedforward_units,\n",
    "            dropout_rate=dropout_rate,\n",
    "            activation=keras.activations.gelu,\n",
    "            normalization_layer=layers.LayerNormalization(epsilon=1e-6),\n",
    "            name=f\"feedforward_{layer_idx}\",\n",
    "        )(features)\n",
    "    # MLP全连接的隐层结果\n",
    "    mlp_hidden_units = [\n",
    "        factor * features.shape[-1] for factor in mlp_hidden_units_factors\n",
    "    ]\n",
    "    # 最终的MLP网络\n",
    "    features = create_mlp(\n",
    "        hidden_units=mlp_hidden_units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        activation=keras.activations.selu,\n",
    "        normalization_layer=layers.BatchNormalization(),\n",
    "        name=\"MLP\",\n",
    "    )(features)\n",
    "    # 添加sigmoid构建二分类器\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\", name=\"sigmoid\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "# 完整的模型\n",
    "baseline_model = create_baseline_model(\n",
    "    embedding_dims=EMBEDDING_DIMS,\n",
    "    num_mlp_blocks=NUM_MLP_BLOCKS,\n",
    "    mlp_hidden_units_factors=MLP_HIDDEN_UNITS_FACTORS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    ")\n",
    "print(\"Total model weights:\", baseline_model.count_params())\n",
    "keras.utils.plot_model(baseline_model, show_shapes=True, rankdir=\"LR\")\n",
    "# Total model weights: 109629"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd0840c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'baseline_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m history \u001b[38;5;241m=\u001b[39m run_experiment(\n\u001b[0;32m----> 2\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[43mbaseline_model\u001b[49m,\n\u001b[1;32m      3\u001b[0m     train_data_file\u001b[38;5;241m=\u001b[39mtrain_data_file,\n\u001b[1;32m      4\u001b[0m     test_data_file\u001b[38;5;241m=\u001b[39mtest_data_file,\n\u001b[1;32m      5\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39mNUM_EPOCHS,\n\u001b[1;32m      6\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mLEARNING_RATE,\n\u001b[1;32m      7\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mWEIGHT_DECAY,\n\u001b[1;32m      8\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'baseline_model' is not defined"
     ]
    }
   ],
   "source": [
    "history = run_experiment(\n",
    "    model=baseline_model,\n",
    "    train_data_file=train_data_file,\n",
    "    test_data_file=test_data_file,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f1beadb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 80\u001b[0m\n\u001b[1;32m     78\u001b[0m     model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39moutputs)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m---> 80\u001b[0m tabtransformer_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_tabtransformer_classifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_transformer_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_TRANSFORMER_BLOCKS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_HEADS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEMBEDDING_DIMS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmlp_hidden_units_factors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMLP_HIDDEN_UNITS_FACTORS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDROPOUT_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal model weights:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tabtransformer_model\u001b[38;5;241m.\u001b[39mcount_params())\n\u001b[1;32m     88\u001b[0m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mplot_model(tabtransformer_model, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rankdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 12\u001b[0m, in \u001b[0;36mcreate_tabtransformer_classifier\u001b[0;34m(num_transformer_blocks, num_heads, embedding_dims, mlp_hidden_units_factors, dropout_rate, use_column_embedding)\u001b[0m\n\u001b[1;32m     10\u001b[0m inputs \u001b[38;5;241m=\u001b[39m create_model_inputs()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 编码特征\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m encoded_categorical_feature_list, numerical_feature_list \u001b[38;5;241m=\u001b[39m \u001b[43mencode_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dims\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 堆叠类别型特征的embeddings，为输入Tansformer做准备\u001b[39;00m\n\u001b[1;32m     16\u001b[0m encoded_categorical_features \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstack(encoded_categorical_feature_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 26\u001b[0m, in \u001b[0;36mencode_inputs\u001b[0;34m(inputs, embedding_dims)\u001b[0m\n\u001b[1;32m     23\u001b[0m         encoded_categorical_feature_list\u001b[38;5;241m.\u001b[39mappend(encoded_categorical_feature)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;66;03m# 数值型特征\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m         numerical_feature \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m         numerical_feature_list\u001b[38;5;241m.\u001b[39mappend(numerical_feature)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoded_categorical_feature_list, numerical_feature_list\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/backend/common/keras_tensor.py:91\u001b[0m, in \u001b[0;36m__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "def create_tabtransformer_classifier(\n",
    "    num_transformer_blocks,\n",
    "    num_heads,\n",
    "    embedding_dims,\n",
    "    mlp_hidden_units_factors,\n",
    "    dropout_rate,\n",
    "    use_column_embedding=False,\n",
    "):\n",
    "    # 构建输入\n",
    "    inputs = create_model_inputs()\n",
    "    # 编码特征\n",
    "    encoded_categorical_feature_list, numerical_feature_list = encode_inputs(\n",
    "        inputs, embedding_dims\n",
    "    )\n",
    "    # 堆叠类别型特征的embeddings，为输入Tansformer做准备\n",
    "    encoded_categorical_features = tf.stack(encoded_categorical_feature_list, axis=1)\n",
    "    # 拼接数值型特征\n",
    "    numerical_features = layers.concatenate(numerical_feature_list)\n",
    "    # embedding\n",
    "    if use_column_embedding:\n",
    "        num_columns = encoded_categorical_features.shape[1]\n",
    "        column_embedding = layers.Embedding(\n",
    "            input_dim=num_columns, output_dim=embedding_dims\n",
    "        )\n",
    "        column_indices = tf.range(start=0, limit=num_columns, delta=1)\n",
    "        encoded_categorical_features = encoded_categorical_features + column_embedding(\n",
    "            column_indices\n",
    "        )\n",
    "    # 构建Transformer块\n",
    "    for block_idx in range(num_transformer_blocks):\n",
    "        # 多头自注意力\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dims,\n",
    "            dropout=dropout_rate,\n",
    "            name=f\"multihead_attention_{block_idx}\",\n",
    "        )(encoded_categorical_features, encoded_categorical_features)\n",
    "        # 第1个跳接/Skip connection\n",
    "        x = layers.Add(name=f\"skip_connection1_{block_idx}\")(\n",
    "            [attention_output, encoded_categorical_features]\n",
    "        )\n",
    "        # 第1个层归一化/Layer normalization\n",
    "        x = layers.LayerNormalization(name=f\"layer_norm1_{block_idx}\", epsilon=1e-6)(x)\n",
    "        # 全连接层\n",
    "        feedforward_output = create_mlp(\n",
    "            hidden_units=[embedding_dims],\n",
    "            dropout_rate=dropout_rate,\n",
    "            activation=keras.activations.gelu,\n",
    "            normalization_layer=layers.LayerNormalization(epsilon=1e-6),\n",
    "            name=f\"feedforward_{block_idx}\",\n",
    "        )(x)\n",
    "        # 第2个跳接/Skip connection\n",
    "        x = layers.Add(name=f\"skip_connection2_{block_idx}\")([feedforward_output, x])\n",
    "        # 第2个层归一化/Layer normalization\n",
    "        encoded_categorical_features = layers.LayerNormalization(\n",
    "            name=f\"layer_norm2_{block_idx}\", epsilon=1e-6\n",
    "        )(x)\n",
    "    # 展平embeddings\n",
    "    categorical_features = layers.Flatten()(encoded_categorical_features)\n",
    "    # 对数值型特征做层归一化\n",
    "    numerical_features = layers.LayerNormalization(epsilon=1e-6)(numerical_features)\n",
    "    # 拼接作为最终MLP的输入\n",
    "    features = layers.concatenate([categorical_features, numerical_features])\n",
    "    # 计算MLP隐层单元\n",
    "    mlp_hidden_units = [\n",
    "        factor * features.shape[-1] for factor in mlp_hidden_units_factors\n",
    "    ]\n",
    "    # 构建最终的MLP.\n",
    "    features = create_mlp(\n",
    "        hidden_units=mlp_hidden_units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        activation=keras.activations.selu,\n",
    "        normalization_layer=layers.BatchNormalization(),\n",
    "        name=\"MLP\",\n",
    "    )(features)\n",
    "    # 添加sigmoid构建二分类\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\", name=\"sigmoid\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "tabtransformer_model = create_tabtransformer_classifier(\n",
    "    num_transformer_blocks=NUM_TRANSFORMER_BLOCKS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    embedding_dims=EMBEDDING_DIMS,\n",
    "    mlp_hidden_units_factors=MLP_HIDDEN_UNITS_FACTORS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    ")\n",
    "print(\"Total model weights:\", tabtransformer_model.count_params())\n",
    "keras.utils.plot_model(tabtransformer_model, show_shapes=True, rankdir=\"LR\")\n",
    "#Total model weights: 87479"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d388ef74",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tabtransformer_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m history \u001b[38;5;241m=\u001b[39m run_experiment(\n\u001b[0;32m----> 2\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[43mtabtransformer_model\u001b[49m,\n\u001b[1;32m      3\u001b[0m     train_data_file\u001b[38;5;241m=\u001b[39mtrain_data_file,\n\u001b[1;32m      4\u001b[0m     test_data_file\u001b[38;5;241m=\u001b[39mtest_data_file,\n\u001b[1;32m      5\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39mNUM_EPOCHS,\n\u001b[1;32m      6\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mLEARNING_RATE,\n\u001b[1;32m      7\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mWEIGHT_DECAY,\n\u001b[1;32m      8\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tabtransformer_model' is not defined"
     ]
    }
   ],
   "source": [
    "history = run_experiment(\n",
    "    model=tabtransformer_model,\n",
    "    train_data_file=train_data_file,\n",
    "    test_data_file=test_data_file,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a3b422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
